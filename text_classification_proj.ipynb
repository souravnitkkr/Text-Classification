{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages required for the project\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A list of common english words which should not affect predictions\n",
    "stopwords = ['a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone',\n",
    "             'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst', 'amount',\n",
    "             'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are', 'around',\n",
    "             'as', 'at', 'back', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before',\n",
    "             'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', 'beyond', 'bill', 'both',\n",
    "             'bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant', 'co', 'con', 'could', 'couldnt', 'cry', 'de',\n",
    "             'describe', 'detail', 'did', 'do', 'does', 'doing', 'don', 'done', 'down', 'due', 'during', 'each', 'eg',\n",
    "             'eight', 'either', 'eleven', 'else', 'elsewhere', 'empty', 'enough', 'etc', 'evening', 'ever', 'every', 'everyone',\n",
    "             'everything', 'everywhere', 'except', 'few', 'fifteen', 'fify', 'fill', 'find', 'fire', 'first', 'five', 'for',\n",
    "             'former', 'formerly', 'forty', 'found', 'four', 'from', 'front', 'full', 'further', 'get', 'give', 'go', 'had',\n",
    "             'has', 'hasnt', 'have', 'having', 'he', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon',\n",
    "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', 'hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed',\n",
    "             'interest', 'into', 'is', 'it', 'its', 'itself', 'just', 'keep', 'last', 'latter', 'latterly', 'least', 'less',\n",
    "             'ltd', 'made', 'many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine', 'more', 'moreover', 'most', 'mostly',\n",
    "             'move', 'much', 'must', 'my', 'myself', 'name', 'namely', 'neither', 'never', 'nevertheless', 'next', 'nine',\n",
    "             'no', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of', 'off', 'often', 'on', 'once',\n",
    "             'one', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'own',\n",
    "             'part', 'per', 'perhaps', 'please', 'put', 'rather', 're', 's', 'same', 'see', 'seem', 'seemed', 'seeming',\n",
    "             'seems', 'serious', 'several', 'she', 'should', 'show', 'side', 'since', 'sincere', 'six', 'sixty', 'so', \n",
    "             'some', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhere', 'still', 'such', 'system',\n",
    "             't', 'take', 'ten', 'than', 'that', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'there',\n",
    "             'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they', 'thickv', 'thin', 'third', 'this',\n",
    "             'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'top', 'toward',\n",
    "             'towards', 'twelve', 'twenty', 'two', 'un', 'under', 'until', 'up', 'upon', 'us', 'very', 'via', 'was', 'we',\n",
    "             'well', 'were', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby',\n",
    "             'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom',\n",
    "             'whose', 'why', 'will', 'with', 'within', 'without', 'would', 'yet', 'you', 'your', 'yours', 'yourself',\n",
    "             'yourselves']\n",
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # an element of X is represented as (filename,text)\n",
    "Y = [] # an element of Y represents the newsgroup category of the corresponding X element\n",
    "for category in os.listdir('20_newsgroups'):\n",
    "    for document in os.listdir('20_newsgroups/'+category):\n",
    "        with open('20_newsgroups/'+category+'/'+document, \"r\") as f:\n",
    "            X.append((document,f.read()))\n",
    "            Y.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a vocabulary of words from the given documents\n",
    "vocab = {}\n",
    "for i in range(len(X_train)):\n",
    "    word_list = []\n",
    "    for word in X_train[i][1].split():\n",
    "        word_new  = word.strip(string.punctuation).lower()\n",
    "        if (len(word_new)>2)  and (word_new not in stopwords):  \n",
    "            if word_new in vocab:\n",
    "                vocab[word_new]+=1\n",
    "            else:\n",
    "                vocab[word_new]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16224\n"
     ]
    }
   ],
   "source": [
    "#sorting the words on the basis of freq in decreasing order\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "sorted_vocab = sorted(vocab.items(), key=itemgetter(1),reverse=True)\n",
    "print(sorted_vocab[0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the first 1000 frequent words as the final_vocab\n",
    "final_vocab={}\n",
    "i=0\n",
    "for index in sorted_vocab:\n",
    "    if(i<1000):\n",
    "        final_vocab[index[0]]=index[1]\n",
    "        i=i+1\n",
    "    else:\n",
    "        break\n",
    "features = []\n",
    "for key in final_vocab:\n",
    "        features.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "{'subject': 16224, 'lines': 15659, 'date': 15558, 'newsgroups': 15278, 'path': 15246, 'message-id': 15051, 'apr': 14784, 'organization': 14770, 'gmt': 13305, '1993': 11104, 'writes': 10997, 'references': 9745, 'article': 9419, 'sender': 8179, 'people': 7548, \"don't\": 7534, 'like': 7507, 'university': 7416, 'know': 6667, 'nntp-posting-host': 6431, 'think': 5873, 'use': 5126, 'time': 5010, \"it's\": 4943, \"i'm\": 4900, 'new': 4839, 'good': 4669, 'xref': 4566, 'cantaloupe.srv.cs.cmu.edu': 4558, 'say': 3904, 'make': 3858, 'way': 3831, 'news': 3694, 'distribution': 3592, 'right': 3544, 'god': 3539, 'world': 3336, 'want': 3305, 'said': 3157, 'used': 3142, 'need': 3069, \"max>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax\": 3065, 'really': 2955, 'work': 2946, 'believe': 2807, 'problem': 2761, 'computer': 2746, 'years': 2522, \"i've\": 2508, 'information': 2481, 'help': 2453, 'going': 2439, 'state': 2418, 'using': 2403, 'better': 2381, 'point': 2373, 'government': 2359, 'things': 2337, 'file': 2325, 'question': 2284, 'thanks': 2265, 'reply-to': 2249, \"can't\": 2221, 'windows': 2205, 'read': 2193, 'sure': 2170, 'usa': 2169, 'usenet': 2140, \"doesn't\": 2117, 'number': 2098, 'david': 2052, 'got': 2047, 'case': 2023, 'thing': 2016, 'year': 2007, 'fact': 1976, 'data': 1945, 'look': 1922, 'program': 1916, \"that's\": 1912, 'drive': 1900, 'space': 1899, 'available': 1895, 'come': 1878, 'science': 1863, 'version': 1857, 'software': 1843, 'little': 1824, 'long': 1806, 'law': 1798, 'john': 1792, 'best': 1771, 'power': 1770, 'day': 1762, 'true': 1754, \"didn't\": 1753, 'probably': 1727, 'different': 1722, 'tue': 1721, 'public': 1707, 'fri': 1706, 'set': 1687, 'group': 1672, 'actually': 1667, 'try': 1666, 'jesus': 1660, 'tell': 1651, 'course': 1632, 'lot': 1615, 'great': 1606, 'car': 1600, 'game': 1578, 'list': 1566, 'real': 1563, 'systems': 1534, 'run': 1534, 'says': 1531, 'far': 1517, 'mean': 1513, 'support': 1512, 'research': 1473, 'thu': 1458, 'life': 1458, \"you're\": 1458, 'possible': 1452, 'free': 1450, 'wrong': 1439, 'second': 1436, 'yes': 1435, 'sun': 1429, \"i'd\": 1426, 'reason': 1425, 'message': 1412, 'post': 1407, 'old': 1404, 'let': 1397, 'card': 1383, 'called': 1379, 'hard': 1366, 'mon': 1365, 'line': 1355, 'key': 1349, 'able': 1347, 'place': 1342, \"isn't\": 1338, 'end': 1336, 'looking': 1335, 'seen': 1331, 'christian': 1326, 'send': 1322, 'bad': 1320, 'order': 1317, 'problems': 1316, 'man': 1315, 'bit': 1310, 'technology': 1308, 'center': 1307, 'maybe': 1306, 'team': 1303, 'example': 1302, 'general': 1290, 'following': 1288, 'person': 1285, 'quite': 1276, 'files': 1272, 'wrote': 1266, 'internet': 1265, 'access': 1264, 'email': 1263, 'thought': 1255, 'trying': 1244, 'means': 1236, 'wed': 1233, 'heard': 1232, 'high': 1229, 'mark': 1224, 'jews': 1221, 'chip': 1220, 'control': 1215, 'window': 1211, 'given': 1202, 'idea': 1199, 'national': 1189, 'evidence': 1187, 'human': 1186, 'opinions': 1186, 'children': 1185, 'kind': 1179, 'e-mail': 1178, 'away': 1178, 'word': 1177, 'mail': 1174, 'phone': 1168, 'image': 1166, 'keywords': 1164, 'times': 1160, 'book': 1155, 'michael': 1148, 'getting': 1147, 'start': 1128, 'big': 1127, 'left': 1119, 'gun': 1108, 'makes': 1106, 'note': 1104, 'remember': 1104, 'saying': 1103, 'questions': 1102, 'israel': 1096, 'info': 1086, \"i'll\": 1085, 'source': 1084, 'based': 1077, 'home': 1074, 'department': 1072, 'institute': 1070, 'followup-to': 1070, 'change': 1070, 'code': 1069, 'today': 1058, 'net': 1055, 'price': 1049, 'standard': 1046, 'stuff': 1045, 'small': 1035, 'graphics': 1032, 'money': 1024, 'ask': 1023, 'bible': 1020, 'answer': 1015, 'american': 1008, 'agree': 1002, 'rights': 1001, 'paul': 996, 'steve': 991, 'local': 983, 'running': 981, 'told': 981, 'ago': 979, 'issue': 978, 'president': 978, 'large': 975, 'matter': 974, 'games': 974, 'address': 973, 'approved': 967, 'days': 967, 'religion': 963, 'interested': 963, 'hope': 961, 'works': 959, 'states': 958, 'came': 958, 'pretty': 955, 'buy': 948, 'claim': 947, 'mac': 946, 'mike': 946, 'love': 945, 'sale': 943, 'open': 934, \"there's\": 931, 'care': 931, 'original': 930, 'box': 929, 'college': 929, 'current': 927, 'jim': 927, 'machine': 921, 'april': 919, 'feel': 916, 'war': 916, 'simply': 915, 'canada': 909, 'network': 909, 'church': 908, 'history': 907, 'live': 906, 'fax': 906, 'play': 901, 'mind': 897, 'dos': 896, 'engineering': 896, 'understand': 895, 'fbi': 894, 'pay': 893, \"won't\": 889, 'speed': 885, 'robert': 885, 'including': 882, 'important': 881, 'turkish': 876, 'disk': 875, 'christians': 871, 'truth': 871, 'private': 869, 'started': 867, 'dept': 866, 'service': 865, 'health': 865, 'include': 860, 'wanted': 854, 'went': 853, 'type': 852, 'posting': 852, 'comes': 850, 'cause': 845, \"wouldn't\": 843, 'certainly': 841, 'instead': 838, 'encryption': 838, 'hand': 837, 'area': 836, 'making': 833, 'clipper': 832, 'working': 830, 'copy': 829, 'rec.sport.hockey': 828, 'black': 827, 'video': 826, 'programs': 822, 'memory': 822, 'country': 820, 'guess': 816, 'unix': 816, 'armenian': 815, 'value': 815, 'x-newsreader': 813, 'consider': 812, 'jewish': 811, 'white': 811, 'christ': 810, 'later': 809, 'ftp': 809, 'men': 804, 'difference': 803, 'unless': 800, 'california': 799, 'u.s': 798, 'win': 797, 'death': 797, 'house': 793, 'server': 793, 'tried': 791, 'faith': 788, 'write': 787, 'hell': 787, 'company': 778, 'opinion': 775, 'cost': 775, 'earth': 772, 'police': 769, 'contact': 764, '1.1': 763, 'sat': 760, 'objective': 760, 'soc.religion.christian': 758, 'scsi': 758, 'morality': 758, 'rec.sport.baseball': 755, 'single': 754, 'san': 752, 'display': 750, 'words': 750, 'sort': 749, 'religious': 748, 'nice': 747, 'deal': 747, 'dead': 746, 'frank': 746, 'sense': 745, 'user': 745, 'view': 744, 'especially': 743, 'clear': 743, 'argument': 742, 'christian@aramis.rutgers.edu': 741, 'color': 739, 'likely': 738, 'talking': 737, 'major': 734, 'anybody': 731, 'school': 730, 'james': 723, 'services': 722, 'hockey': 721, 'check': 720, 'similar': 719, 'certain': 718, '100': 717, 'provide': 716, 'dave': 713, 'simple': 713, 'taken': 713, 'killed': 713, 'correct': 710, 'common': 710, 'couple': 709, 'armenians': 709, 'tin': 709, 'comp.sys.mac.hardware': 708, 'light': 708, 'rec.motorcycles': 707, 'summary': 707, 'asked': 707, 'moral': 705, 'theory': 702, 'happened': 701, \"he's\": 699, 'saw': 698, 'press': 698, 'books': 696, 'stop': 696, 'city': 692, 'fine': 691, 'text': 691, 'alt.atheism': 690, 'monitor': 688, 'exactly': 686, 'political': 685, 'goes': 684, 'package': 684, 'reading': 682, 'players': 682, 'known': 680, 'account': 679, 'usually': 678, 'position': 677, 'sorry': 676, 'security': 673, 'israeli': 673, 'personal': 672, 'board': 672, 'peter': 671, 'laws': 671, 'brian': 669, 'statement': 668, 'situation': 665, 'sound': 664, \"they're\": 664, 'application': 664, 'comp.sys.ibm.pc.hardware': 663, 'clinton': 662, 'society': 661, 'division': 661, 'fast': 661, 'discussion': 660, 'advance': 659, 'took': 659, 'interesting': 658, 'body': 657, 'washington': 656, 'york': 653, 'experience': 652, 'hardware': 651, 'rest': 651, 'rec.autos': 650, 'written': 649, \"we're\": 648, 'needs': 646, 'needed': 646, 'insurance': 644, 'force': 643, 'uses': 642, 'guy': 640, 'hear': 640, 'groups': 639, 'low': 639, 'night': 639, 'exist': 638, 'office': 638, 'users': 638, 'form': 637, 'sci.electronics': 635, 'easy': 634, 'size': 634, 'western': 634, 'happen': 633, 'ibm': 632, 'screen': 632, 'according': 632, 'months': 632, 'particular': 632, 'test': 631, \"haven't\": 630, 'bob': 629, 'past': 628, 'women': 627, 'turn': 625, 'koresh': 624, 'period': 624, 'format': 624, 'ones': 623, \"let's\": 621, 'business': 620, 'hit': 617, 'corporation': 617, 'head': 616, 'level': 616, 'early': 616, 'medical': 615, 'article-i.d': 614, 'accept': 612, 'error': 610, 'sci.med': 609, 'study': 609, 'texas': 608, 'radio': 606, 'manager': 606, 'model': 604, 'apple': 604, 'members': 603, 'special': 603, 'longer': 603, 'guns': 603, 'numbers': 603, 'project': 602, 'bike': 602, 'shall': 601, 'effect': 600, 'kill': 599, \"what's\": 597, 'red': 596, 'lost': 596, 'communications': 595, 'sell': 594, 'future': 592, 'add': 592, 'recently': 592, 'comp.windows.x': 592, 'faq': 592, 'peace': 591, 'expect': 590, 'talk': 587, 'worth': 586, 'coming': 586, 'posted': 585, 'keys': 585, 'series': 584, \"wasn't\": 582, 'gets': 582, 'sci.space': 582, 'taking': 580, 'process': 579, 'season': 579, 'images': 577, 'united': 577, 'christianity': 577, 'toronto': 575, 'ground': 575, 'plus': 572, 'drivers': 572, 'federal': 571, 'job': 570, 'considered': 570, 'driver': 570, 'comp.graphics': 569, 'week': 568, 'offer': 567, 'outside': 566, 'i.e': 563, 'mode': 563, \"aren't\": 562, 'doubt': 562, 'short': 561, 'face': 561, 'cases': 560, 'results': 559, 'bbs': 558, 'specific': 558, 'thinking': 557, 'lord': 555, 'points': 554, 'various': 553, 'story': 553, 'league': 553, 'baseball': 553, 'action': 552, 'speak': 552, 'involved': 552, 'policy': 551, 'tom': 551, 'cars': 550, 'performance': 549, 'explain': 548, 'military': 548, 'return': 547, 'gas': 547, 'weapons': 546, 'assume': 546, 'international': 546, 'young': 546, 'total': 545, 'reference': 543, 'result': 542, 'necessary': 542, 'talk.politics.guns': 542, '0400': 542, 'looks': 541, 'water': 541, 'response': 540, 'values': 539, 'soon': 539, 'land': 539, 'act': 538, 'andrew': 538, 'design': 537, 'thomas': 536, 'hold': 534, 'eric': 532, 'freedom': 529, 'report': 527, 'million': 526, 'deleted': 525, 'legal': 525, 'sources': 523, 'near': 523, 'friend': 522, 'build': 522, 'previous': 519, 'pittsburgh': 519, 'comp.os.ms-windows.misc': 519, 'ideas': 519, 'close': 518, 'output': 518, 'claims': 518, '1992': 517, 'wants': 517, 'richard': 517, 'crime': 516, 'allow': 516, 'voice': 516, 'computing': 516, \"couldn't\": 516, 'bus': 516, 'runs': 515, 'knows': 515, 'willing': 514, 'includes': 514, 'section': 514, 'leave': 513, 'technical': 511, 'development': 510, 'parts': 510, 'knowledge': 510, 'scott': 509, 'choice': 509, 'sin': 509, 'clearly': 509, 'road': 507, 'population': 507, 'save': 507, 'issues': 507, 'rate': 506, 'building': 504, 'tape': 504, 'present': 503, 'comments': 503, 'asking': 502, 'universe': 502, 'smith': 502, 'chris': 501, 'media': 500, 'appreciated': 499, 'sent': 497, 'child': 497, 'rules': 496, 'higher': 496, 'strong': 495, 'germany': 495, 'sci.crypt': 495, 'reply': 494, 'ram': 494, 'disclaimer': 492, 'reasons': 492, 'takes': 492, 'currently': 491, 'exists': 491, 'anonymous': 491, 'sounds': 489, 'player': 488, 'nature': 487, 'included': 487, 'ways': 486, 'air': 486, 'boston': 486, 'quality': 486, 'completely': 485, \"god's\": 484, 'cover': 484, 'mouse': 484, 'newsgroup': 484, 'purpose': 483, 'applications': 483, 'jon': 482, 'appears': 480, 'field': 480, 'nasa': 480, 'machines': 479, 'useful': 479, 'mentioned': 479, 'directory': 478, 'waco': 478, 'court': 478, 'genocide': 477, 'complete': 476, 'basis': 476, 'gives': 475, 'main': 475, 'living': 474, 'univ': 474, 'drives': 474, 'die': 473, 'north': 472, 'george': 470, 'belief': 469, 'abortion': 467, 'cut': 467, 'site': 467, 'follow': 466, 'keith': 466, 'meaning': 465, 'scientific': 465, 'inside': 465, 'batf': 464, 'armenia': 463, 'built': 463, 'son': 463, 'manual': 462, 'algorithm': 462, 'ide': 462, 'muslim': 460, 'drug': 459, 'existence': 459, 'individual': 458, 'faster': 458, 'created': 458, 'command': 458, 'suggest': 457, 'bought': 456, 'modem': 455, 'in-reply-to': 454, 'atheists': 454, 'secret': 453, 'dan': 453, 'average': 453, 'father': 453, 'lots': 451, 'term': 451, 'cards': 451, 'community': 451, 'dod': 450, 'supposed': 450, 'illinois': 448, 'necessarily': 448, 'create': 448, 'chicago': 448, 'family': 448, 'weeks': 447, 'noise': 446, 'views': 446, 'administration': 446, 'america': 446, 'obviously': 446, 'basic': 445, 'south': 445, 'required': 444, '3.1': 444, 'normal': 444, 'difficult': 444, 'arms': 444, 'chance': 443, 'serial': 442, 'gave': 441, 'shot': 441, 'thank': 441, 'entry': 441, 'muslims': 440, 'finally': 440, '2000': 440, 'coverage': 440, 'attack': 440, 'wait': 439, 'looked': 439, 'launch': 439, 'language': 438, \"you'll\": 438, 'events': 437, 'illegal': 437, 'directly': 437, 'page': 436, 'paper': 436, 'advice': 436, 'food': 435, 'folks': 435, 'event': 435, 'turkey': 435, 'cable': 433, 'base': 431, 'plan': 429, 'motif': 428, 'wish': 428, 'tim': 426, 'cheap': 426, 'learn': 425, 'figure': 425, 'reasonable': 425, 'mass': 425, 'function': 424, 'terms': 424, 'entire': 423, 'digital': 423, 'carry': 423, 'device': 423, 'reality': 422, 'actions': 422, 'definition': 422, 'wonder': 421, 'pat': 421, 'controller': 421, 'arab': 421, 'hours': 420, 'party': 420, 'context': 420, 'request': 420, 'responsible': 419, 'engine': 419, 'class': 418, 'matthew': 418, 'rule': 417, 'final': 416, 'lives': 416, 'details': 415, 'room': 415, 'library': 414, 'related': 413, 'poster': 413, 'record': 413, 'received': 413, 'places': 412, 'prove': 411, 'limited': 410, 'died': 410, 'changed': 410, 'unfortunately': 409, 'commercial': 409, \"you've\": 409, 'break': 409, 'edt': 408, 'method': 408, 'facts': 408, 'nhl': 408, 'blue': 407, 'station': 407, 'stated': 406, 'wondering': 405, 'happens': 405, 'fan': 404, 'lead': 404, 'devices': 403, 'market': 403, 'recent': 402, 'condition': 401, 'allowed': 400, 'products': 400, 'extra': 399, 'volume': 399, 'reports': 399, 'miles': 398, 'product': 398, 'gary': 398, 'online': 398, 'equipment': 397, 'generally': 397, 'object': 397, 'green': 396, 'mention': 396, 'bring': 396, 'compound': 395, 'defense': 395, 'hedrick@athos.rutgers.edu': 394, 'analysis': 394, 'laboratory': 393, 'owner': 392, 'release': 392, 'easily': 391, 'companies': 391, 'widget': 391, 'happy': 391, 'half': 391, 'russian': 391, 'suppose': 390, 'knew': 390, 'evil': 390, 'reported': 389, 'joseph': 389, 'tax': 388, 'designed': 388, 'originator': 388, 'king': 388, 'joe': 387, 'citizens': 387, 'ray': 387, 'street': 386, 'stupid': 386, 'sex': 386, 'regarding': 386, 'hate': 386, 'printer': 386, 'age': 386, 'continue': 385, 'trouble': 384, 'official': 384, 'btw': 384, 'late': 384, 'west': 383, 'author': 383, 'safety': 382, 'letter': 382, 'corp': 382, 'apparently': 382, 'des': 381, 'turks': 380, 'attempt': 380, 'require': 380, 'door': 380, 'europe': 380, 'physical': 379, 'east': 379, 'congress': 379, 'privacy': 379, 'port': 379, 'forget': 378, 'interface': 378, 'title': 378, 'stephen': 378, 'ken': 378, 'lack': 377, 'oil': 377, 'conference': 377, 'teams': 376, 'imagine': 376, 'yeah': 375, 'starting': 375, 'georgia': 375, 'friends': 374, 'greek': 374, 'obvious': 373, 'americans': 373, 'studies': 373, 'decided': 373, 'guys': 372, 'disease': 372, 'solution': 371, 'enforcement': 371, 'held': 371, 'watch': 370, 'drugs': 370, 'microsoft': 370, 'authority': 369, 'gone': 368, 'worked': 368, 'material': 368, 'stand': 368, 'protect': 368, 'colorado': 368, 'internal': 367, 'goal': 367, 'apply': 366, 'quote': 366, 'false': 366, 'appear': 365, 'excellent': 365, 'environment': 365, 'homosexuality': 365, 'mormons': 364, 'brought': 364, 'installed': 363, 'misc.forsale': 363, 'lab': 363, 'avoid': 363, 'lower': 361, 'lee': 361, 'wife': 361, 'input': 361, 'suspect': 360, 'unit': 360, 'natural': 358, 'decision': 358, 'choose': 357, 'supply': 357, 'pick': 357, 'month': 356, 'heart': 356, 'resources': 356, 'murder': 356, \"who's\": 355, '1st': 355, 'fans': 355, 'tools': 355}\n"
     ]
    }
   ],
   "source": [
    "print(len(final_vocab))\n",
    "print(final_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To represent training data as word vector counts\n",
    "X_train_dataset = np.zeros((len(X_train),len(features)))\n",
    "# This can take some time to complete\n",
    "for i in range(len(X_train)):\n",
    "    # print(i) # Uncomment to see progress\n",
    "    word_list = [ word.strip(string.punctuation).lower() for word in X_train[i][1].split()]\n",
    "    for word in word_list:\n",
    "        if word in features:\n",
    "            X_train_dataset[i][features.index(word)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To represent test data as word vector counts\n",
    "X_test_dataset = np.zeros((len(X_test),len(features)))\n",
    "# This can take some time to complete\n",
    "for i in range(len(X_test)):\n",
    "    # print(i) # Uncomment to see progress\n",
    "    word_list = [ word.strip(string.punctuation).lower() for word in X_test[i][1].split()]\n",
    "    for word in word_list:\n",
    "        if word in features:\n",
    "            X_test_dataset[i][features.index(word)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn's score on training data : 0.8525705141028206\n",
      "Sklearn's score on testing data : 0.8214\n",
      "Classification report for testing data :-\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.72      0.79      0.75       233\n",
      "           comp.graphics       0.80      0.75      0.78       253\n",
      " comp.os.ms-windows.misc       0.89      0.81      0.85       249\n",
      "comp.sys.ibm.pc.hardware       0.82      0.83      0.83       240\n",
      "   comp.sys.mac.hardware       0.83      0.90      0.86       236\n",
      "          comp.windows.x       0.89      0.85      0.87       240\n",
      "            misc.forsale       0.71      0.88      0.79       261\n",
      "               rec.autos       0.83      0.91      0.87       269\n",
      "         rec.motorcycles       0.83      0.94      0.88       284\n",
      "      rec.sport.baseball       0.94      0.96      0.95       248\n",
      "        rec.sport.hockey       0.96      0.96      0.96       231\n",
      "               sci.crypt       0.93      0.85      0.89       233\n",
      "         sci.electronics       0.79      0.84      0.81       244\n",
      "                 sci.med       0.82      0.86      0.84       256\n",
      "               sci.space       0.87      0.88      0.87       246\n",
      "  soc.religion.christian       0.93      0.98      0.96       252\n",
      "      talk.politics.guns       0.70      0.81      0.75       249\n",
      "   talk.politics.mideast       0.92      0.73      0.81       281\n",
      "      talk.politics.misc       0.64      0.52      0.57       259\n",
      "      talk.religion.misc       0.57      0.39      0.46       236\n",
      "\n",
      "               micro avg       0.82      0.82      0.82      5000\n",
      "               macro avg       0.82      0.82      0.82      5000\n",
      "            weighted avg       0.82      0.82      0.82      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using sklearn's Multinomial Naive Bayes\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_dataset,Y_train)\n",
    "Y_test_pred = clf.predict(X_test_dataset)\n",
    "sklearn_score_train = clf.score(X_train_dataset,Y_train)\n",
    "print(\"Sklearn's score on training data :\",sklearn_score_train)\n",
    "sklearn_score_test = clf.score(X_test_dataset,Y_test)\n",
    "print(\"Sklearn's score on testing data :\",sklearn_score_test)\n",
    "print(\"Classification report for testing data :-\")\n",
    "print(classification_report(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Multinomial Naive Bayes from scratch\n",
    "class MultinomialNaiveBayes:\n",
    "    \n",
    "    def __init__(self):\n",
    "        # count is a dictionary which stores several dictionaries corresponding to each news category\n",
    "        # each value in the subdictionary represents the freq of the key corresponding to that news category \n",
    "        self.count = {}\n",
    "        # classes represents the different news categories\n",
    "        self.classes = None\n",
    "    \n",
    "    def fit(self,X_train,Y_train):\n",
    "        # This can take some time to complete       \n",
    "        self.classes = set(Y_train)\n",
    "        for class_ in self.classes:\n",
    "            self.count[class_] = {}\n",
    "            for i in range(len(X_train[0])):\n",
    "                self.count[class_][i] = 0\n",
    "            self.count[class_]['total'] = 0\n",
    "            self.count[class_]['total_points'] = 0\n",
    "        self.count['total_points'] = len(X_train)\n",
    "        \n",
    "        for i in range(len(X_train)):\n",
    "            for j in range(len(X_train[0])):\n",
    "                self.count[Y_train[i]][j]+=X_train[i][j]\n",
    "                self.count[Y_train[i]]['total']+=X_train[i][j]\n",
    "            self.count[Y_train[i]]['total_points']+=1\n",
    "    \n",
    "    def __probability(self,test_point,class_):\n",
    "        \n",
    "        log_prob = np.log(self.count[class_]['total_points']) - np.log(self.count['total_points'])\n",
    "        total_words = len(test_point)\n",
    "        for i in range(len(test_point)):\n",
    "            current_word_prob = test_point[i]*(np.log(self.count[class_][i]+1)-np.log(self.count[class_]['total']+total_words))\n",
    "            log_prob += current_word_prob\n",
    "        \n",
    "        return log_prob\n",
    "    \n",
    "    \n",
    "    def __predictSinglePoint(self,test_point):\n",
    "        \n",
    "        best_class = None\n",
    "        best_prob = None\n",
    "        first_run = True\n",
    "        \n",
    "        for class_ in self.classes:\n",
    "            log_probability_current_class = self.__probability(test_point,class_)\n",
    "            if (first_run) or (log_probability_current_class > best_prob) :\n",
    "                best_class = class_\n",
    "                best_prob = log_probability_current_class\n",
    "                first_run = False\n",
    "                \n",
    "        return best_class\n",
    "        \n",
    "  \n",
    "    def predict(self,X_test):\n",
    "        # This can take some time to complete\n",
    "        Y_pred = [] \n",
    "        for i in range(len(X_test)):\n",
    "        # print(i) # Uncomment to see progress\n",
    "            Y_pred.append( self.__predictSinglePoint(X_test[i]) )\n",
    "        \n",
    "        return Y_pred\n",
    "    \n",
    "    def score(self,Y_pred,Y_true):\n",
    "        # returns the mean accuracy\n",
    "        count = 0\n",
    "        for i in range(len(Y_pred)):\n",
    "            if Y_pred[i] == Y_true[i]:\n",
    "                count+=1\n",
    "        return count/len(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our score on testing data : 0.8214\n",
      "Classification report for testing data :-\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.72      0.79      0.75       233\n",
      "           comp.graphics       0.80      0.75      0.78       253\n",
      " comp.os.ms-windows.misc       0.89      0.81      0.85       249\n",
      "comp.sys.ibm.pc.hardware       0.82      0.83      0.83       240\n",
      "   comp.sys.mac.hardware       0.83      0.90      0.86       236\n",
      "          comp.windows.x       0.89      0.85      0.87       240\n",
      "            misc.forsale       0.71      0.88      0.79       261\n",
      "               rec.autos       0.83      0.91      0.87       269\n",
      "         rec.motorcycles       0.83      0.94      0.88       284\n",
      "      rec.sport.baseball       0.94      0.96      0.95       248\n",
      "        rec.sport.hockey       0.96      0.96      0.96       231\n",
      "               sci.crypt       0.93      0.85      0.89       233\n",
      "         sci.electronics       0.79      0.84      0.81       244\n",
      "                 sci.med       0.82      0.86      0.84       256\n",
      "               sci.space       0.87      0.88      0.87       246\n",
      "  soc.religion.christian       0.93      0.98      0.96       252\n",
      "      talk.politics.guns       0.70      0.81      0.75       249\n",
      "   talk.politics.mideast       0.92      0.73      0.81       281\n",
      "      talk.politics.misc       0.64      0.52      0.57       259\n",
      "      talk.religion.misc       0.57      0.39      0.46       236\n",
      "\n",
      "               micro avg       0.82      0.82      0.82      5000\n",
      "               macro avg       0.82      0.82      0.82      5000\n",
      "            weighted avg       0.82      0.82      0.82      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf2 = MultinomialNaiveBayes()\n",
    "clf2.fit(X_train_dataset,Y_train)\n",
    "Y_test_pred = clf2.predict(X_test_dataset)\n",
    "our_score_test = clf2.score(Y_test_pred,Y_test)  \n",
    "print(\"Our score on testing data :\",our_score_test)\n",
    "print(\"Classification report for testing data :-\")\n",
    "print(classification_report(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of our model on test data: 0.8214\n",
      "Score of inbuilt sklearn's MultinomialNB on the same data : 0.8214\n"
     ]
    }
   ],
   "source": [
    "print(\"Score of our model on test data:\",our_score_test)\n",
    "print(\"Score of inbuilt sklearn's MultinomialNB on the same data :\",sklearn_score_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
